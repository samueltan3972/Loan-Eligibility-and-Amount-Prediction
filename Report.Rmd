---
title: "Group Project Report"
output: html_document
date: "2022-12-29"
---

# Introduction

### Team member

| Name                  | Student ID |
|-----------------------|------------|
| Samuel Tan Joo Woon   | S2196123   |
| Chandra Mohan         | 22050516   |
| Ng Boon Sheng         | 22050617   |
| Nurul Auni            | 17098058   |
| Siti Norhafiza Jahaya | S2181108   |

## Project Objective

A bank wants to automate the loan eligibility process based on customer details submitted through online application form. The details filled by the customer are Gender, Marital Status, Education, Number of Dependents, Income of self and co applicant, Required Loan Amount, Required Loan Term, Credit History and others. The requirements are as follows:

1.  Check eligibility of the Customer given the inputs described above. (Classification)
2.  Predict loan amount to be approved given the inputs described above. (Regression)

## Project Methodology

This project is using OSEMN model.

**OBTAIN:** The dataset is obtain through [Kaggle](https://www.kaggle.com/datasets/yashpaloswal/loan-prediction-with-3-problem-statement). The link is as followed: <https://www.kaggle.com/datasets/yashpaloswal/loan-prediction-with-3-problem-statement>

**SCRUB:** The dataset come with splitted training set, testing set and sample_submission in csv file. Some action have been taken in data cleaning process to clean and generate new training and testing set.

1.  Combine training and testing set and sample_submission
2.  Dealing with missing value
3.  Convert to 100k unit on Loan Amount
4.  Label encoding for categorical data
5.  Split into new training and testing set

**EXPLORATORY:**

**MODEL:**

Listed below are the machine learning algorithms that will be used in regression modelling for loan amount approval prediction:
1. Extreme Gradient Boosting (XGBoost)
2. Support Vector Regression (SVR)
3. K-Nearest Neighbor(KNN)
4. Linear Regression
5. Random Forest (RF)

**INTEPRET:**

For regression modelling:
Root Mean Square Error (RMSE) and R Squared value will be used to evaluate the performance of model developed and the best model will be chosen as the final model for loan amount approval prediction.

------------------------------------------------------------------------

# 1. Data Cleaning

#### 1.0 Import the necessary library

```{r}
if(!require("dplyr")) { install.packages("dplyr")  }
if(!require('tidyr')) { install.packages('tidyr') }
if(!require('DescTools')) { install.packages('DescTools') }
if(!require('VIM')) { install.packages('VIM') }

library(dplyr)
library('tidyr')
library('DescTools')
library('VIM')

setwd(dirname(rstudioapi::getSourceEditorContext()$path))

```

#### 1.1 Combine dataset into one new dataset

```{r}
# Prequel: Combine all dataset into one new dataset
training_set = read.csv("./Data/training_set.csv")
testing_set = read.csv("./Data/testing_set.csv")
sample_submission = read.csv("./Data/sample_submission.csv")

head(sample_submission)
head(testing_set)

## combine testing set with its approval status
combined_testing_sample = inner_join(testing_set, sample_submission[, c("Loan_ID", "Loan_Status")], by = "Loan_ID")
head(combined_testing_sample)


## Check if colnames is matched
print(colnames(training_set) == colnames(combined_testing_sample))
combined_training_testing = rbind(combined_testing_sample,training_set) %>% arrange(Loan_ID)
head(combined_training_testing)

## Write new combined dataset
write.csv(combined_training_testing, "./Data/combined_training_testing.csv", row.names = FALSE)

dataset = read.csv("./Data/combined_training_testing.csv")
head(dataset)
```

#### 1.2 Check and deal the missing value

```{r}
# Check number of empty value in a dataset
print.numOfEmtpyValue <- function(data) {
  # create empty matrix
  df <- data.frame(matrix(ncol = 2, nrow = 0))
  colnames(df) = c("Column_Names", "Num_Of_Empty_Value")
  
  for(i in 1:ncol(data)) {
    df[nrow(df) + 1,] <- c(colnames(data)[i], sum(is.na(data[, i])|is.null(data[, i])|data[, i] == ""))
  }
  print(df)
}

# Convert column that have empty string to NA
dataset = na_if(dataset, "")
print.numOfEmtpyValue(dataset)
```

#### 1.3 Impute the missing value according to the attribute nature

```{r}
# 1.3.1 Sequential, Random Hot deck imputation on categorical Columns with less empty value (Married, Education)
dataset = hotdeck(dataset, variable = c("Married"), domain_var = c("Gender", "Dependents", "Education", "Self_Employed", "Credit_History", "Loan_Status"), imp_var=FALSE)
dataset = hotdeck(dataset, variable = c("Education"), domain_var = c("Gender", "Dependents", "Married", "Self_Employed", "Credit_History", "Loan_Status"), imp_var=FALSE)

print.numOfEmtpyValue(dataset)

# 1.3.2 KNN -> Dependents, Self_Employed, Credit_History, Loan_Amount_Term
dataset = kNN(dataset, variable = c("Dependents"), dist_var = c("Gender", "Education", "Married", "Self_Employed", "Credit_History", "Loan_Status"), imp_var=FALSE)
dataset = kNN(dataset, variable = c("Self_Employed"), dist_var = c("Gender", "Dependents", "Married", "Education", "Credit_History", "Loan_Status"), imp_var=FALSE)
dataset = kNN(dataset, variable = c("Credit_History"), dist_var = c("Gender", "Dependents", "Married", "Self_Employed", "Education", "Loan_Status"), imp_var=FALSE)
dataset = kNN(dataset, variable = c("Loan_Amount_Term"), dist_var = c("ApplicantIncome", "CoapplicantIncome", "LoanAmount", "property_Area", "Credit_History", "Loan_Status"), imp_var=FALSE)

print.numOfEmtpyValue(dataset)

# 1.3.3 Regression Imputation -> ApplicantIncome, CoapplicantIncome, LoanAmount
dataset = regressionImp(ApplicantIncome~Gender+Self_Employed, data=dataset, imp_var=FALSE)
dataset = regressionImp(LoanAmount~Gender+Dependents+Married+Self_Employed+ApplicantIncome+CoapplicantIncome+Credit_History+property_Area+Loan_Status, data=dataset, imp_var=FALSE)

# 1.3.4 Replace NA value in "CoapplicantIncome" with 0 (default value)
dataset["CoapplicantIncome"] = dataset$CoapplicantIncome %>% replace_na(0)

# Check on the missing value
print.numOfEmtpyValue(dataset)
```

#### 1.4 Remove unnecessary column and Convert Loan Amount into 100k base

```{r}
# 1.4.1 Remove unimportant column
dataset <- subset (dataset, select = -c(Loan_ID, Gender))

# 1.4.2 Convert LoanAmount into 100k base
dataset["LoanAmount"] = round(dataset["LoanAmount"] * 1000)

head(dataset)
```

#### 1.5 Apply label encoding on the categorical data

```{r}
dataset$Married = ifelse(dataset$Married == "Yes", 1, 0)
dataset['Dependents'][dataset['Dependents'] == "3+"] = 3
dataset$Education = ifelse(dataset$Education == "Graduate", 1, 0)
dataset$Self_Employed = ifelse(dataset$Self_Employed == "Yes", 1, 0)
dataset$property_Area = as.numeric(factor(dataset$property_Area))
dataset$Loan_Status = ifelse(dataset$Loan_Status == "Y", 1, 0)
```

#### 1.6 Split the data into new training and testing set

```{r}
# 1.6 Split into training and testing set
set.seed(1)
sample <- sample(c(TRUE, FALSE), nrow(dataset), replace=TRUE, prob=c(0.8,0.2))
training_set  <- dataset[sample, ]
testing_set   <- dataset[!sample, ]

write.csv(dataset, "./Data/processed_dataset.csv", row.names = FALSE)
write.csv(training_set, "./Data/processed_training_set.csv", row.names = FALSE)
write.csv(testing_set, "./Data/processed_testing_set.csv", row.names = FALSE)

reg_dataset=dataset[dataset$Loan_Status==1,]
reg_sample = sample(c(TRUE, FALSE), nrow(reg_dataset), replace=TRUE, prob=c(0.8,0.2))
reg_training_set  = reg_dataset[reg_sample, ]
reg_testing_set   = reg_dataset[!reg_sample, ]

write.csv(reg_dataset, "./Data/reg_processed_dataset.csv", row.names = FALSE)
write.csv(reg_training_set, "./Data/reg_processed_training_set.csv", row.names = FALSE)
write.csv(reg_testing_set, "./Data/reg_processed_testing_set.csv", row.names = FALSE)

glimpse(training_set)
glimpse(testing_set)
```

# 2. EDA

#### Import library

```{r}
#install.packages('ggplot', repos = "http://cran.us.r-project.org")
#install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require("ggplot2")) { install.packages("ggplot2")  }
if(!require('tidyverse')) { install.packages('tidyverse') }

library(ggplot2)
library(tidyverse)
```

#### Create df to avoid mess up with other variable

```{r}
df = dataset

df$Married <- as.factor(df$Married)
df$Dependents <- as.factor(df$Dependents)
df$Education <- as.factor(df$Education)
df$Self_Employed <- as.factor(df$Self_Employed)
df$ApplicantIncome <- as.numeric(df$ApplicantIncome)
df$CoapplicantIncome <- as.numeric(df$CoapplicantIncome)
df$LoanAmount <- as.numeric(df$LoanAmount)
df$Loan_Amount_Term <- as.numeric(df$Loan_Amount_Term)
df$Credit_History <- as.factor(df$Credit_History)
df$property_Area <- as.factor(df$property_Area)
df$Loan_Status <- as.factor(df$Loan_Status)
```

#### Summary of dataset

```{r}
summary(df)
```

#### distribution of Applications Income

```{r}
ggplot(df , aes(x=ApplicantIncome,bins=5,fill=Loan_Status))+
  geom_histogram()+theme_bw()+
  labs(x="Income of Applicants",
       y= "Number of Applicants",
       title ="Distribution of Applicant's Income")
```

#### Number of Married People

```{r}

plot.married <- ggplot(df, aes(x = Married, fill = Loan_Status)) +
  geom_bar()

ggplot(df, aes(x = Education, fill = Loan_Status)) +
  geom_bar(position = "fill") +
  labs(y = "Approval Status", x = 'Education Level') + ggtitle(' Education level vs Loan Status')
```

#### Education Level seems like does not make any difference.

```{r}
ggplot(data = df, aes(LoanAmount)) + geom_histogram(binwidth = 10000)
```

# 3. Classification - To check loan eligibility of the customer

5 Classification algorithms:

1.  Logistic Regression
2.  Support Vector Machine
3.  Naive Bayes
4.  Decision Tree
5.  XGBoost

#### Install packages for data manipulation, visualization and model training

```{r}
#install.packages("tidyverse", repos = "http://cran.us.r-project.org")
#install.packages("caret", repos = "http://cran.us.r-project.org")
#install.packages("MLmetrics", repos = "http://cran.us.r-project.org")
if(!require("tidyverse")) { install.packages("tidyverse")  }
if(!require("caret")) { install.packages("caret")  }
if(!require('MLmetrics')) { install.packages('MLmetrics') }

library(tidyverse)
library(caret)
library(MLmetrics)
```

#### Performance function

```{r}

get_performance_v1 <- function(y_true, y_pred){
  library(MLmetrics)
  # Convert predicted probabilities to binary labels
  y_pred_binary <- as.factor(ifelse(y_pred > 0.5, "1", "0"))
  # Convert true labels to factor
  y_true <- as.factor(y_true)
  # Make sure that the levels of y_true and y_pred_binary are the same
  levels(y_pred_binary) <- levels(y_true)
  # Confusion matrix
  cm <- confusionMatrix(y_pred_binary, y_true)
  # Accuracy
  acc <- cm$overall[1]
  # Precision
  prec <- cm$byClass[1]
  # Recall
  rec <- cm$byClass[2]
  # F1-score
  f1 <- F1_Score(y_pred_binary, y_true)
  # Return a list of evaluation metrics
  return(list(accuracy = acc, precision = prec, recall = rec, f1_score = f1, confusion_matrix = cm))
}
```

```{r}
#Read split dataset
train_set <- read.csv("./Data/processed_training_set.csv")
test_set <- read.csv("./Data/processed_testing_set.csv")

# Split train set into data (x_train) and target(y_train)
x_train <- train_set[,!names(train_set) %in% "Loan_Status"]
y_train = train_set$Loan_Status

# Split test set into data (x_test) and target(y_test)
x_test <- test_set[,!names(test_set) %in% "Loan_Status"]
y_test <- test_set$Loan_Status
```

#### 3.1 Logistic Regression

```{r}
#Building of model
set.seed(1)
logistic_def <- glm(formula = y_train ~ ., data = x_train, family = "binomial")

#Prediction using model
logistic_def_pred <- predict(logistic_def, newdata = x_test, type = "response")

#Evaluate model performance
logistic_def_result <- get_performance_v1(y_test, logistic_def_pred)
```

#### 3.2 Support Vector Machine

```{r}
#install.packages("e1071", repos = "http://cran.us.r-project.org")
if(!require('e1071')) { install.packages('e1071') }
library(e1071)

#Building of model
set.seed(1)
svm_model_def <- svm(y_train ~ ., data = x_train, kernel = "linear", cost = 1)

#Prediction using model
svm_pred_def <- predict(svm_model_def, x_test)

#Evaluate model performance
svm_result_def <- get_performance_v1(y_test, svm_pred_def)
```

#### 3.3 Naive Bayes

```{r}
#Building of model
set.seed(1)
nb_model_def <- naiveBayes(x_train, y_train)

#Prediction using model
nb_pred_def <- predict(nb_model_def, x_test)

#Evaluate model performance
nb_pred_def_numeric <- as.numeric(nb_pred_def)
nb_result_def <- get_performance_v1(y_test, nb_pred_def_numeric)
```

#### 3.4 Decision Tree

```{r}
#Install packages for data manipulation, visualization and model training
#install.packages("rpart", repos = "http://cran.us.r-project.org")

if(!require('rpart')) { install.packages('rpart') }
library(rpart)

#Building of model
set.seed(1)
dt_model_def <- rpart(formula = y_train ~ ., data = x_train)

#Prediction using model
dt_pred_def <- predict(dt_model_def, x_test)

#Evaluate model performance
dt_result_def <- get_performance_v1(y_test, dt_pred_def)
```

#### 3.5 XGBoost

```{r}
#Install packages for data manipulation, visualization and model training
#install.packages("xgboost", repos = "http://cran.us.r-project.org")
if(!require('xgboost')) { install.packages('xgboost') }
library(xgboost)

# convert data to matrix
x_train_matrix <- as.matrix(x_train)
x_test_matrix <- as.matrix(x_test)

#Building of model
set.seed(1)
xgb_model_def <- xgboost(data = x_train_matrix, label = y_train, nrounds = 100, objective = "binary:logistic")

#Prediction using model
xgb_pred_def <- predict(xgb_model_def, x_test_matrix)

#Evaluate model performance
xgb_result_def <- get_performance_v1(y_test, xgb_pred_def)
```

#### Final result dataframe to evaluate all models under classification

```{r}
model_results_df <- data.frame(
       Model = c("Logistic Regression", "SVM", "Naive Bayes", "Decision Tree", "XGBoost"),
       Accuracy = c(logistic_def_result$accuracy, svm_result_def$accuracy, nb_result_def$accuracy, dt_result_def$accuracy, xgb_result_def$accuracy),
       Precision = c(logistic_def_result$precision, svm_result_def$precision, nb_result_def$precision, dt_result_def$precision, xgb_result_def$precision),
       Recall = c(logistic_def_result$recall, svm_result_def$recall, nb_result_def$recall, dt_result_def$recall, xgb_result_def$recall),
       F1_Score = c(logistic_def_result$f1_score, svm_result_def$f1_score, nb_result_def$f1_score, dt_result_def$f1_score, xgb_result_def$f1_score))

print(model_results_df)
```

# 4. Regression - If customer is not eligible for the input required amount and duration, what can be amount for the given duration

5 Regression algorithms

1.  XGBoost
2.  Support Vector Regression
3.  K-Nearest Neighbor
4.  Linear Regression
5.  Random Forest

#### Data import

```{r cars}
train_set = read.csv("./Data/reg_processed_training_set.csv")
test_set = read.csv("./Data/reg_processed_testing_set.csv")
head(train_set) # shows the first 6 rows of train set
```

#### Split train set into data (x_train) and label(y_train)

```{r}
x_train = train_set[,!names(train_set) %in% c("LoanAmount","Loan_Status")]
y_train = train_set$LoanAmount
head(y_train)
```

#### Split test set into data (x_test) and label(y_test)

```{r}
x_test=test_set[,!names(test_set) %in% c("LoanAmount","Loan_Status")]
y_test=test_set$LoanAmount
head(y_test)
```

#### Function-Customised function to be called

```{r}
get_performance = function(arg1, arg2){
mse = mean((arg1 - arg2) ^ 2)
mae = caret::MAE(arg1, arg2)
rmse = caret::RMSE(arg1, arg2)
measure = postResample(pred = arg2, obs = arg1)
r_squared = measure[2]
cat("MSE: ", mse, "MAE: ", mae, " RMSE: ", rmse,"RSquared: ", r_squared)
output = list(mse,mae,rmse,r_squared)
return(output)
}
```

#### 4.1 XGBoost

#### Import Library

```{r}
if(!require("xgboost")) { install.packages("xgboost")  }
if(!require("caret")) { install.packages("caret")  }
library(xgboost)
library(caret)
set.seed(1)
```

#### XGBoost-Default Parameters

```{r}
xgb_train = xgb.DMatrix(data = as.matrix(x_train), label = y_train)
xgb_test = xgb.DMatrix(data = as.matrix(x_test), label = y_test)
xgboost_def = xgboost(data = xgb_train,nrounds =50)
#xgboost_def
xgboost_def_predict = predict(xgboost_def, xgb_test)
xgboost_def_result=get_performance(y_test,xgboost_def_predict)
```

#### XGBoost-Fine tuned with GridSearchCV

#### Parameters

```{r}
grid_tune <- expand.grid(
  nrounds = c(500,1000,1500), #number of trees
  max_depth = c(2,4,6),
  eta = c(0.025,0.05,0.1,0.3), #Learning rate
  gamma = c(0.05, 0.1, 0.5, 0.7, 0.9, 1.0),
  colsample_bytree = c(0.4, 0.6, 0.8, 1.0), #subsample ratio of columns for tree
  min_child_weight = c(1,2,3), # the larger, the more conservative the model is; can be used as a stop
  subsample = c(0.5, 0.75, 1.0) # used to prevent overfitting by sampling X% training
)
```

#### Grid tuning
This step is commented due to grid tuning requires long time to complete during every compilation, thus only the best parameters tuned (ran previously) are stored and will be implemented in this project.
```{r}
train_control <- trainControl(method = "cv", number=10,verboseIter = TRUE,allowParallel = TRUE)

#Commented as time consuming to run, but the best parameters are as below:
#xgb_tune <- train(x = x_train,y = y_train,trControl = train_control,tuneGrid = grid_tune,method= "xgbTree",verbose = TRUE)

#xgb_tune$bestTune
#xgb_tune
```
RMSE was used to select the optimal model using the smallest value. The final values used for the model were nrounds = 500, max_depth = 2, eta = 0.025, gamma = 0.9, colsample_bytree = 0.6, min_child_weight = 3 and subsample = 0.5.
```{r}
final_tune=expand.grid(
  nrounds = 500,
  max_depth = 2,
  eta = 0.025, 
  gamma =  0.9,
  colsample_bytree = 0.6, 
  min_child_weight = 3, 
  subsample = 0.5
  ) 

xgb_tuned <- train(x = x_train,y = y_train,trControl = train_control,tuneGrid = final_tune,method= "xgbTree",verbose = TRUE)
#xgb_tuned
xgb_tuned_pred <- predict(xgb_tuned, x_test)
xgboost_tuned_result=get_performance(y_test,xgb_tuned_pred)
```

#### 4.2 Support Vector Regression (SVR)
#### Support Vector Regression (SVR)-Default Parameters

```{r}
if(!require("e1071")) { install.packages("e1071")  }
if(!require("kernlab")) { install.packages("kernlab")  }
library(e1071)
library(kernlab)
svr_def <- svm(formula=y_train ~ . , data=x_train,method = 'svmRadial')
#svr_def
svr_def_pred <- predict(svr_def, x_test)
svr_def_result=get_performance(y_test,svr_def_pred)
```

#### Support Vector Regression-Fine tuned with GridSearchCV

#### Parameters

```{r}
set.seed(1)
svr_grid_tune <- expand.grid(
  C = c(0.01, 0.25, 0.5, 1,10,100),
  sigma = 0.1
)
```

#### Grid tuning

```{r}
svr_train_control <- trainControl(method = "cv", number=10)
svr_tuned <- train(x = x_train,y = y_train,trControl = svr_train_control,tuneGrid = svr_grid_tune,method = 'svmRadial',verbose = TRUE)
#svr_tuned$bestTune
#svr_tuned
svr_tuned_pred=predict(svr_tuned,x_test)
svr_tuned_result=get_performance(y_test,svr_tuned_pred)
```

#### 4.3 KNN

#### KNN-Default Parameters

```{r}
knn_def = knnreg(x_train, y_train)
#knn_def
knn_def_pred = predict(knn_def, x_test)
knn_def_result=get_performance(y_test,knn_def_pred)
```

#### KNN-Fine tuned with GridSearchCV

#### Parameters

```{r}
set.seed(1)
knn_grid_tune <- expand.grid(
  k = 1:50
  )
```

#### Grid tuning

```{r}
knn_train_control <- trainControl(method = "cv", number=10)
knn_tuned <- train(x = x_train,y = y_train,trControl = knn_train_control,tuneGrid = knn_grid_tune,method = 'knn',verbose = TRUE)
#knn_tuned$bestTune
#knn_tuned
knn_tuned_pred=predict(knn_tuned,x_test)
knn_tuned_result=get_performance(y_test,knn_tuned_pred)
```

#### 4.4 Linear Regression(LM)

#### Linear Regression(LM)-Default Parameter

```{r}
# Build Training model
lm_model <- train(x = x_train, y = y_train,method = "lm", trControl = trainControl(method='none'))
summary(lm_model)

# Apply model for prediction
#Model_training <-predict(lm_model, x_train) # Apply model to make prediction on Training set
Model_testing <-predict(lm_model, x_test) # Apply model to make prediction on Testing set
#summary(Model_testing)
#summary(Model_training)
lm_def_result=get_performance(y_test,Model_testing)
```

#### 4.5 Random Forest

#### Random Forest (RF) - Deafult Parameters

```{r}
library(randomForest)
library(caret)

# Build Training model, bootstrap
rf_def <- train(x = x_train, y = y_train ,method = "ranger")
#rf_def
rf_def_pred=predict(rf_def,x_test)
rf_def_result=get_performance(y_test,rf_def_pred)
```

### Random Forest (RF) - Fine tuned with Grid

```{r}
# K-Fold Cross Validation
ctrl<- trainControl(method="cv", number=10)
# Hyperparameter Tuning

tgrid <- expand.grid(
  mtry = 2:4,
  splitrule = "variance",
  min.node.size = c(5,10, 20)
)

rf_tuned = train(x = x_train, y = y_train,trControl = ctrl,method = "ranger",tuneGrid = tgrid)
#rf_tuned

# Apply model to make prediction on Testing set
rf_tuned_predict = predict(rf_tuned, x_test)
rf_tuned_result = get_performance(y_test, rf_tuned_predict)
```

#### Final Result DataFrame
A summary of the regression mdodels developed on respective Mean Square Error (MSE), Mean Absolute Error (MAE). Root Mean Square Error (RMSE) and R Squared values.
```{r}
Name = c('XGBoost-Default','XGBosot-Grid Tuned','SVM Regression-Default','SVM Regression-Grid Tune','kNN-Default','kNN-Grid Tune','Linear Regression-Default','Random Forest-Default','Random Forest-Grid Tuned')
MSE = c(xgboost_def_result[[1]],xgboost_tuned_result[[1]],
      svr_def_result[[1]],svr_tuned_result[[1]],
      knn_def_result[[1]],knn_tuned_result[[1]],
      lm_def_result[[1]],
      rf_def_result[[1]],rf_tuned_result[[1]])

MAE = c(xgboost_def_result[[2]],xgboost_tuned_result[[2]],
      svr_def_result[[2]],svr_tuned_result[[2]],
      knn_def_result[[2]],knn_tuned_result[[2]],
      lm_def_result[[2]],
      rf_def_result[[2]],rf_tuned_result[[2]])

RMSE = c(xgboost_def_result[[3]],xgboost_tuned_result[[3]],
      svr_def_result[[3]],svr_tuned_result[[3]],
      knn_def_result[[3]],knn_tuned_result[[3]],
      lm_def_result[[3]],
      rf_def_result[[3]],rf_tuned_result[[3]])

R_SQUARED =c (xgboost_def_result[[4]],xgboost_tuned_result[[4]],
      svr_def_result[[4]],svr_tuned_result[[4]],
      knn_def_result[[4]],knn_tuned_result[[4]],
      lm_def_result[[4]],
      rf_def_result[[4]],rf_tuned_result[[4]])

df <- data.frame(Name,MSE,MAE,RMSE,R_SQUARED)
print (df)
```

### Plotting of graphs

Bar charts of performance metrices (RMSE and R_Squared) vs Regression models to show model comparisons.

RMSE is the average deviation of the predictions from the observations. It is the measure of how well a regression line fits the data points. Lower RMSE value indicates a better fit of the model to the data as the differences between the predicted and true values are smaller.

R Squared is called the coefficient of determination. It provides goodness of fit of a regression model. The value 0 indicates for no-fit and 1 for perfect fit.

```{r}
library(ggplot2)
#RMSE
ggplot(data=df, aes(x=RMSE, y=Name, fill = RMSE)) +
geom_bar(stat="identity", width=0.8)+
geom_text(aes(label=RMSE), vjust=-0.3, colour="white", size=3.0)+
scale_colour_gradient2()+
theme_classic()+  
ggtitle("RMSE value on different regression models") +
xlab("RMSE") +
ylab("Regression models")
```

Lower RMSE value indicates better fit of the model thus from the bar chart it is observed XGBoost-Grid Tuned model is the best model for this prediction.

```{r}
# R_SQUARED
ggplot(data=df, aes(x=R_SQUARED, y=Name, fill = R_SQUARED)) +
geom_bar(stat="identity", width=0.8)+
geom_text(aes(label=R_SQUARED), vjust=-0.3, colour="white", size=3.0)+
scale_colour_gradient2()+
theme_classic()+  
ggtitle("R Squared value on different regression model") +
xlab("R Squared") +
ylab("Regression models")
```

Value of 1 of R Squared indicates perfect fit, from the bar chart it is observed XGBoost-Grid Tuned model has the highest and nearest value to 1.

Based on the visualization from the RMSE and RSquared Charts plotted, it is observed that XGBoost-Grid Tuned model has the lowest RMSE value and highest R Squared value, thus it will be selected as the final model for loan amount approval prediction regression model. The comparison between actual and predicted value on the test set is plotted:

```{r}
# Predicted vs. Actual Values (XGBoost-Grid Tuned)
options(scipen = 999)
library(scales) 
plot(x=xgb_tuned_pred, y= y_test,
     xlab='Predicted Values',
     ylab='Actual Values',
     main='Actual vs Predicted Values (XGBoost-Grid Tuned)')
abline(a=0, b=1)
```

Overview on actual vs predictions of new loan amount using XGBoost tuned prediction model

```{r}
data <- data.frame(actual= y_test, predicted=xgb_tuned_pred)
head(data)
```
------------------------------------------------------------------------

# Conclusion
In conclusion, two final prediction models are developed in this project made up of one loan approval classification prediction model and one loan amount approved regression prediction model.

@Hafiza, please fill in your conclusion on classification modelling.

In predicting the loan amount to be approved for customer, XGBoost regression model is the best model among the 5 models developed as it has the lowest Root Mean Square Error (RMSE) and highest R Squared value. However, there is still a room for improvement for the model to fit better on the dataset in future development.
